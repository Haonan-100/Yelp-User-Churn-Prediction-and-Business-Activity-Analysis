{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2 | User Churn Labeling & Feature Engineering\n",
    "\n",
    "This section labels users as churned or active based on their review activity and engineers both static and behavioral features for downstream modeling. It is organized into the following steps:\n",
    "\n",
    "| Step | Section                                | Description                                                                                                                                                |\n",
    "| ---- | -------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------- |\n",
    "| 0    | Imports & Global Constants             | Load libraries, define raw/processed paths, set project‑wide constants and helper functions (`clean_state`, `safe_read_json`).                              |\n",
    "| 1    | Churn Label Generation                 | Stream through the review data to extract each user’s last review date, then assign a binary `churn_label` based on a 365‑day inactivity cutoff.          |\n",
    "| 2    | User Static Features                   | Read `user.json`, select key fields (`review_count`, `average_stars`, `fans`, etc.), derive `friends_count`, `elite_years`, and `member_years`.               |\n",
    "| 3    | Behavioral Features                    | Chunk‑aggregate per-user reaction counts (`useful`, `funny`, `cool`), review statistics (count/mean/variance), and average text length.                      |\n",
    "| 4    | Merging & Missing Value Handling       | Left‑join churn labels, static features, and behavioral aggregates into a single DataFrame, drop unneeded columns, and fill numeric NaNs with zeros.        |\n",
    "| 5    | Save Features                          | Write the final feature table to `data/processed/user_churn_features.csv`.                                                                                 |\n",
    "| 6    | Train/Test Split (Time‑based Stratify) | Split users into train and test sets by last review date relative to the cutoff, and save the ID lists to `train_user_ids.txt` and `test_user_ids.txt`. |\n",
    "\n",
    "\n",
    "\n"
   ],
   "id": "e25177839588e83b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T22:08:53.289131Z",
     "start_time": "2025-05-13T22:08:53.022439Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 0 | Imports & Global Constants\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "RAW   = Path(\"../data/raw\")\n",
    "PROC  = Path(\"../data/processed\");  PROC.mkdir(exist_ok=True)\n",
    "\n",
    "T_END        = pd.Timestamp(\"2022-01-19\")   # by part 1\n",
    "WINDOW_DAYS  = 365\n",
    "CUTOFF_DATE  = T_END - pd.Timedelta(days=WINDOW_DAYS)"
   ],
   "id": "b823bad1ff7a27a4",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T22:08:53.864726Z",
     "start_time": "2025-05-13T22:08:53.862105Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def clean_state(df, col=\"state\"):\n",
    "    mask = ~df[col].str.match(r\"^[A-Z]{2}$\", na=False)\n",
    "    df.loc[mask, col] = \"XX\"\n",
    "    return df"
   ],
   "id": "28c90cd78a06d28a",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T22:08:55.075374Z",
     "start_time": "2025-05-13T22:08:55.072788Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def safe_read_json(fname, usecols=None, chunksize=None):\n",
    "    path = RAW / fname\n",
    "    if chunksize:\n",
    "        # Read in chunks and yield them\n",
    "        reader = pd.read_json(path, lines=True, encoding=\"utf-8\", chunksize=chunksize)\n",
    "        for chunk in reader:\n",
    "            yield chunk[usecols] if usecols else chunk\n",
    "    else:\n",
    "        df = pd.read_json(path, lines=True, encoding=\"utf-8\")\n",
    "        return df[usecols] if usecols else df"
   ],
   "id": "7058fc017bb457a0",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T22:09:58.049866Z",
     "start_time": "2025-05-13T22:08:56.409882Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 1 | gey `churn_label`\n",
    "last_review = {}\n",
    "for chunk in tqdm(\n",
    "    safe_read_json(\n",
    "        \"yelp_academic_dataset_review.json\",\n",
    "        usecols=[\"user_id\", \"date\"],\n",
    "        chunksize=200_000\n",
    "    ),\n",
    "    desc=\"Scanning reviews\"\n",
    "):\n",
    "    chunk = chunk.copy()\n",
    "    chunk.loc[:, \"date\"] = pd.to_datetime(chunk[\"date\"], errors=\"coerce\")\n",
    "\n",
    "    grp = chunk.groupby(\"user_id\")[\"date\"].max()\n",
    "\n",
    "    for uid, dt_ in grp.items():\n",
    "        if (uid not in last_review) or (dt_ > last_review[uid]):\n",
    "            last_review[uid] = dt_\n",
    "\n",
    "user_last_df = (\n",
    "    pd.Series(last_review, name=\"last_review_date\")\n",
    "      .to_frame()\n",
    "      .reset_index()\n",
    "      .rename(columns={\"index\": \"user_id\"})\n",
    ")\n",
    "user_last_df[\"churn_label\"] = (user_last_df[\"last_review_date\"] < CUTOFF_DATE).astype(int)\n",
    "user_last_df.head()\n"
   ],
   "id": "df25761313022a1b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning reviews: 35it [00:59,  1.69s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                  user_id    last_review_date  churn_label\n",
       "0  ---2PmXbF47D870stH1jqA 2019-04-27 17:35:51            1\n",
       "1  ---UgP94gokyCDuB5zUssA 2021-09-17 17:36:13            0\n",
       "2  --4AjktZiHowEIBCMd4CZA 2019-12-26 17:46:25            1\n",
       "3  --6PFZka7og6Khaw6oyjvQ 2017-10-15 02:19:43            1\n",
       "4  --E0uVPphTORm_OiZ5KCvA 2018-04-05 23:30:41            1"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>last_review_date</th>\n",
       "      <th>churn_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>---2PmXbF47D870stH1jqA</td>\n",
       "      <td>2019-04-27 17:35:51</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>---UgP94gokyCDuB5zUssA</td>\n",
       "      <td>2021-09-17 17:36:13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>--4AjktZiHowEIBCMd4CZA</td>\n",
       "      <td>2019-12-26 17:46:25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>--6PFZka7og6Khaw6oyjvQ</td>\n",
       "      <td>2017-10-15 02:19:43</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>--E0uVPphTORm_OiZ5KCvA</td>\n",
       "      <td>2018-04-05 23:30:41</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T22:09:58.092194Z",
     "start_time": "2025-05-13T22:09:58.073303Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 1.5 Re-label churn based on fixed anchor (T_END)\n",
    "ANCHOR = pd.Timestamp(\"2021-01-19\")          # T_END - 365 days\n",
    "\n",
    "user_last_df[\"churn_label\"] = (user_last_df[\"last_review_date\"] < ANCHOR).astype(int)\n",
    "print(\"label Global Distribution:\\n\", user_last_df[\"churn_label\"].value_counts())"
   ],
   "id": "e3f173339fcdf8a4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label Global Distribution:\n",
      " churn_label\n",
      "1    1670849\n",
      "0     317080\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T22:10:55.487147Z",
     "start_time": "2025-05-13T22:09:58.119202Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 2 | User Static Features (from `user.json`)\n",
    "user_cols = [\n",
    "    \"user_id\", \"review_count\", \"average_stars\",\n",
    "    \"fans\", \"friends\", \"elite\", \"yelping_since\", \"useful\", \"funny\", \"cool\"\n",
    "]\n",
    "user_df = pd.read_json(\n",
    "    RAW/\"yelp_academic_dataset_user.json\",\n",
    "    lines=True,\n",
    "    encoding=\"utf-8\"\n",
    ")[user_cols].copy()\n",
    "\n",
    "user_df[\"friends\"] = user_df[\"friends\"].fillna(\"\")\n",
    "user_df[\"friends_count\"] = user_df[\"friends\"].str.split(\", \").str.len()\n",
    "\n",
    "s = user_df[\"elite\"].str.split(\",\").str.len().fillna(0)\n",
    "s = s.infer_objects(copy=False)\n",
    "user_df[\"elite_years\"] = s.astype(int)\n",
    "\n",
    "user_df[\"yelping_since\"] = pd.to_datetime(user_df[\"yelping_since\"], errors=\"coerce\")\n",
    "user_df[\"member_years\"] = (T_END.year - user_df[\"yelping_since\"].dt.year + 1)\n",
    "\n",
    "user_df = user_df.drop(columns=[\"friends\", \"elite\", \"yelping_since\"])\n",
    "\n",
    "user_df.head()"
   ],
   "id": "7a2abdec30bfab94",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                  user_id  review_count  average_stars  fans  useful  funny  \\\n",
       "0  qVc8ODYU5SZjKXVBgXdI7w           585           3.91   267    7217   1259   \n",
       "1  j14WgRoU_-2ZE1aw1dXrJg          4333           3.74  3138   43091  13066   \n",
       "2  2WnXYQFK0hXEoTxPtV2zvg           665           3.32    52    2086   1010   \n",
       "3  SZDeASXq7o05mMNLshsdIA           224           4.27    28     512    330   \n",
       "4  hA5lMy-EnncsH4JoR-hFGQ            79           3.54     1      29     15   \n",
       "\n",
       "    cool  friends_count  elite_years  member_years  \n",
       "0   5994          14995            1            16  \n",
       "1  27281           4646           14            14  \n",
       "2   1003            381            5            15  \n",
       "3    299            131            3            18  \n",
       "4      7             27            1            16  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>review_count</th>\n",
       "      <th>average_stars</th>\n",
       "      <th>fans</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>cool</th>\n",
       "      <th>friends_count</th>\n",
       "      <th>elite_years</th>\n",
       "      <th>member_years</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>qVc8ODYU5SZjKXVBgXdI7w</td>\n",
       "      <td>585</td>\n",
       "      <td>3.91</td>\n",
       "      <td>267</td>\n",
       "      <td>7217</td>\n",
       "      <td>1259</td>\n",
       "      <td>5994</td>\n",
       "      <td>14995</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>j14WgRoU_-2ZE1aw1dXrJg</td>\n",
       "      <td>4333</td>\n",
       "      <td>3.74</td>\n",
       "      <td>3138</td>\n",
       "      <td>43091</td>\n",
       "      <td>13066</td>\n",
       "      <td>27281</td>\n",
       "      <td>4646</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2WnXYQFK0hXEoTxPtV2zvg</td>\n",
       "      <td>665</td>\n",
       "      <td>3.32</td>\n",
       "      <td>52</td>\n",
       "      <td>2086</td>\n",
       "      <td>1010</td>\n",
       "      <td>1003</td>\n",
       "      <td>381</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SZDeASXq7o05mMNLshsdIA</td>\n",
       "      <td>224</td>\n",
       "      <td>4.27</td>\n",
       "      <td>28</td>\n",
       "      <td>512</td>\n",
       "      <td>330</td>\n",
       "      <td>299</td>\n",
       "      <td>131</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hA5lMy-EnncsH4JoR-hFGQ</td>\n",
       "      <td>79</td>\n",
       "      <td>3.54</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T04:10:43.970109Z",
     "start_time": "2025-05-13T04:09:37.609417Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 3 | Behavioral Features (`review.json`)\n",
    "behav_chunks = []\n",
    "for chunk in tqdm(\n",
    "    safe_read_json(\"yelp_academic_dataset_review.json\",\n",
    "                   usecols=[\"user_id\",\"stars\",\"useful\",\"funny\",\"cool\",\"text\"],\n",
    "                   chunksize=200_000),\n",
    "    desc=\"Behavior aggs\"\n",
    "):\n",
    "    chunk = chunk.copy()\n",
    "    chunk[\"text_len\"] = chunk[\"text\"].str.len()\n",
    "\n",
    "    aggs = {\n",
    "        \"useful\":   \"sum\",\n",
    "        \"funny\":    \"sum\",\n",
    "        \"cool\":     \"sum\",\n",
    "        \"stars\":    [\"count\", \"mean\", \"var\"],\n",
    "        \"text_len\": \"sum\",\n",
    "    }\n",
    "    g = chunk.groupby(\"user_id\").agg(aggs)\n",
    "    g.columns = [\"_\".join(map(str, c)).strip() for c in g.columns]\n",
    "    behav_chunks.append(g)\n",
    "\n",
    "behav_df = (\n",
    "    pd.concat(behav_chunks)\n",
    "      .groupby(\"user_id\")\n",
    "      .sum(numeric_only=True)\n",
    "      .reset_index()\n",
    ")\n",
    "\n",
    "behav_df[\"avg_len\"]    = behav_df[\"text_len_sum\"] / behav_df[\"stars_count\"]\n",
    "behav_df[\"rating_std\"] = (behav_df[\"stars_var\"] / behav_df[\"stars_count\"]).pow(0.5)\n",
    "\n",
    "behav_df = behav_df.drop(columns=[\"text_len_sum\", \"stars_var\"])\n",
    "\n",
    "behav_df = behav_df.rename(columns=lambda x: x.replace(\"text_<lambda_0>\", \"avg_len\"))\n",
    "\n",
    "behav_df.head()"
   ],
   "id": "413f1e4cba946026",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Behavior aggs: 35it [01:01,  1.76s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                  user_id  useful_sum  funny_sum  cool_sum  stars_count  \\\n",
       "0  ---1lKK3aKOuomHnwAkAow           0          0         0            1   \n",
       "1  ---2PmXbF47D870stH1jqA          45          3        23           28   \n",
       "2  ---UgP94gokyCDuB5zUssA           7          0         2           11   \n",
       "3  ---fa6ZK37T9NjkGKI4oSg           1          0         0            1   \n",
       "4  ---r61b7EpVPkb4UVme5tA           8          2         3            5   \n",
       "\n",
       "   stars_mean     avg_len  rating_std  \n",
       "0         5.0  637.000000    0.000000  \n",
       "1        95.0  469.928571    0.000000  \n",
       "2        36.5  459.636364    0.213201  \n",
       "3         1.0  175.000000    0.000000  \n",
       "4        15.0  429.000000    0.000000  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>useful_sum</th>\n",
       "      <th>funny_sum</th>\n",
       "      <th>cool_sum</th>\n",
       "      <th>stars_count</th>\n",
       "      <th>stars_mean</th>\n",
       "      <th>avg_len</th>\n",
       "      <th>rating_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>---1lKK3aKOuomHnwAkAow</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>637.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>---2PmXbF47D870stH1jqA</td>\n",
       "      <td>45</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>28</td>\n",
       "      <td>95.0</td>\n",
       "      <td>469.928571</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>---UgP94gokyCDuB5zUssA</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>36.5</td>\n",
       "      <td>459.636364</td>\n",
       "      <td>0.213201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>---fa6ZK37T9NjkGKI4oSg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>175.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>---r61b7EpVPkb4UVme5tA</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>15.0</td>\n",
       "      <td>429.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T05:34:30.053769Z",
     "start_time": "2025-05-13T05:34:23.059783Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 4 | Merging & Missing Value Handling\n",
    "feat_df = (\n",
    "    user_last_df\n",
    "      .merge(user_df,  on=\"user_id\", how=\"left\")\n",
    "      .merge(behav_df, on=\"user_id\", how=\"left\")\n",
    ")\n",
    "\n",
    "feat_df = feat_df.drop(columns=[\"stars_count\"])\n",
    "\n",
    "num_cols = feat_df.select_dtypes(\"number\").columns\n",
    "feat_df[num_cols] = feat_df[num_cols].fillna(0)\n",
    "\n",
    "leak_cols = [\"days_since_last_review\"]\n",
    "feat_df = feat_df.drop(columns=[c for c in leak_cols if c in feat_df.columns])\n",
    "\n",
    "feat_df.head()"
   ],
   "id": "4b2e386ccd1b1937",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                  user_id    last_review_date  churn_label  review_count  \\\n",
       "0  ---2PmXbF47D870stH1jqA 2019-04-27 17:35:51            1          36.0   \n",
       "1  ---UgP94gokyCDuB5zUssA 2021-09-17 17:36:13            0          16.0   \n",
       "2  --4AjktZiHowEIBCMd4CZA 2019-12-26 17:46:25            1          57.0   \n",
       "3  --6PFZka7og6Khaw6oyjvQ 2017-10-15 02:19:43            1          25.0   \n",
       "4  --E0uVPphTORm_OiZ5KCvA 2018-04-05 23:30:41            1           6.0   \n",
       "\n",
       "   average_stars  fans  useful  funny  cool  friends_count  elite_years  \\\n",
       "0           4.98   3.0    63.0    4.0  36.0          420.0          1.0   \n",
       "1           3.44   1.0     8.0    0.0   3.0            3.0          1.0   \n",
       "2           4.07   0.0    47.0    1.0   5.0            1.0          1.0   \n",
       "3           4.96   3.0    33.0   12.0  23.0           14.0          1.0   \n",
       "4           3.67   0.0     0.0    0.0   0.0            1.0          1.0   \n",
       "\n",
       "   member_years  useful_sum  funny_sum  cool_sum  stars_mean     avg_len  \\\n",
       "0          11.0          45          3        23   95.000000  469.928571   \n",
       "1           9.0           7          0         2   36.500000  459.636364   \n",
       "2           8.0          40          1         3   54.233333  488.291667   \n",
       "3          15.0           5          1         4   39.000000  422.125000   \n",
       "4           5.0           0          0         0   11.000000  805.000000   \n",
       "\n",
       "   rating_std  \n",
       "0    0.000000  \n",
       "1    0.213201  \n",
       "2    0.538774  \n",
       "3    0.000000  \n",
       "4    0.000000  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>last_review_date</th>\n",
       "      <th>churn_label</th>\n",
       "      <th>review_count</th>\n",
       "      <th>average_stars</th>\n",
       "      <th>fans</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>cool</th>\n",
       "      <th>friends_count</th>\n",
       "      <th>elite_years</th>\n",
       "      <th>member_years</th>\n",
       "      <th>useful_sum</th>\n",
       "      <th>funny_sum</th>\n",
       "      <th>cool_sum</th>\n",
       "      <th>stars_mean</th>\n",
       "      <th>avg_len</th>\n",
       "      <th>rating_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>---2PmXbF47D870stH1jqA</td>\n",
       "      <td>2019-04-27 17:35:51</td>\n",
       "      <td>1</td>\n",
       "      <td>36.0</td>\n",
       "      <td>4.98</td>\n",
       "      <td>3.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>420.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>45</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>469.928571</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>---UgP94gokyCDuB5zUssA</td>\n",
       "      <td>2021-09-17 17:36:13</td>\n",
       "      <td>0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>3.44</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>36.500000</td>\n",
       "      <td>459.636364</td>\n",
       "      <td>0.213201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>--4AjktZiHowEIBCMd4CZA</td>\n",
       "      <td>2019-12-26 17:46:25</td>\n",
       "      <td>1</td>\n",
       "      <td>57.0</td>\n",
       "      <td>4.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>54.233333</td>\n",
       "      <td>488.291667</td>\n",
       "      <td>0.538774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>--6PFZka7og6Khaw6oyjvQ</td>\n",
       "      <td>2017-10-15 02:19:43</td>\n",
       "      <td>1</td>\n",
       "      <td>25.0</td>\n",
       "      <td>4.96</td>\n",
       "      <td>3.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>422.125000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>--E0uVPphTORm_OiZ5KCvA</td>\n",
       "      <td>2018-04-05 23:30:41</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.67</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>805.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T05:36:58.359387Z",
     "start_time": "2025-05-13T05:36:58.350162Z"
    }
   },
   "cell_type": "code",
   "source": "print(feat_df[\"churn_label\"].value_counts(dropna=False))",
   "id": "1b88cd7fd29f3f59",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "churn_label\n",
      "1    1670849\n",
      "0     317080\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "execution_count": 54
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T05:37:20.285626Z",
     "start_time": "2025-05-13T05:37:18.819525Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 6-A | Use stratified sampling to split the training and test sets based on labels.\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, test_df = train_test_split(\n",
    "    feat_df, test_size=0.15, stratify=feat_df[\"churn_label\"], random_state=42\n",
    ")\n",
    "\n",
    "train_ids = train_df[\"user_id\"];  test_ids = test_df[\"user_id\"]\n",
    "\n",
    "# ave the list for Part 3 to read\n",
    "train_ids.to_csv(PROC/\"train_user_ids.txt\", index=False, header=False)\n",
    "test_ids .to_csv(PROC/\"test_user_ids.txt\",  index=False, header=False)\n",
    "print(\"✅ ID files updated\")\n",
    "\n",
    "# Visualize the new distribution\n",
    "print(\"train rows:\", len(train_ids), \" test rows:\", len(test_ids))\n",
    "print(\"train label\\n\", train_df[\"churn_label\"].value_counts())\n",
    "print(\"test  label\\n\",  test_df[\"churn_label\"].value_counts())"
   ],
   "id": "2f9244ab37966ca6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ ID files updated\n",
      "train rows: 1689739  test rows: 298190\n",
      "train label\n",
      " churn_label\n",
      "1    1420221\n",
      "0     269518\n",
      "Name: count, dtype: int64\n",
      "test  label\n",
      " churn_label\n",
      "1    250628\n",
      "0     47562\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "execution_count": 55
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T05:35:28.346240Z",
     "start_time": "2025-05-13T05:35:27.591982Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 6-B | Save the new training and testing user ID lists\n",
    "train_ids.to_csv(PROC/\"train_user_ids.txt\", index=False, header=False)\n",
    "test_ids.to_csv( PROC/\"test_user_ids.txt\",  index=False, header=False)\n",
    "print(\"✅ ID files updated: train_user_ids.txt & test_user_ids.txt\")"
   ],
   "id": "fe8cfe1dcb1099c2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ ID files updated: train_user_ids.txt & test_user_ids.txt\n"
     ]
    }
   ],
   "execution_count": 52
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 5,
 "nbformat_minor": 9
}
